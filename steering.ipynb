{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dff1a8c",
   "metadata": {},
   "source": [
    "# Steering an LLM using SAELens\n",
    "\n",
    "This notebook shows how to steer an LLM by making it emphasize a specific feature when responding to a prompt. This notebook is inspired by the [SAELens](https://jbloomaus.github.io/SAELens/) tutorials and by the [Neuronpedia steering feature](https://www.neuronpedia.org/gemma-2-9b-it/steer), and conceptually by Anthropic's famous Golden Gate Bridge example.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "We ran this notebook on a `g6.12xlarge` EC2 instance using the [Deep Learning AMI](https://aws.amazon.com/ai/machine-learning/amis/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d758684",
   "metadata": {},
   "source": [
    "## Identify a specific feature\n",
    "\n",
    "Using [Neuronpedia search](https://www.neuronpedia.org/search-explanations), let's find a feature of interest for the Gemma 2B model. We'll use the pre-built SAE identified as `gemmascope-res-16k`, and drill into layer 20 of that SAE. \n",
    "\n",
    "For this example, I identified feature `4832` as relevant to talking about racing sailboats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7edf17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display\n",
    "\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "def display_dashboard(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=0):\n",
    "    html = get_dashboard_html(sae_release = sae_release, sae_id = sae_id, feature_idx=feature_idx)\n",
    "    print(html)\n",
    "    display(IFrame(html, width=1200, height=600))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b9730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/4832?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/4832?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7149240f99d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_idx = 4832\n",
    "\n",
    "display_dashboard(feature_idx=latent_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19085b71",
   "metadata": {},
   "source": [
    "## Steering\n",
    "\n",
    "Now that we have a feature identified, let's try steering a new output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb310b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor, nn\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig\n",
    ")\n",
    "\n",
    "def steering_hook(\n",
    "    activations: Float[Tensor, \"batch pos d_in\"],\n",
    "    hook: HookPoint,\n",
    "    sae: SAE,\n",
    "    latent_idx: int,\n",
    "    steering_coefficient: float,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Steers the model by returning a modified activations tensor, with some multiple of the steering vector added to all\n",
    "    sequence positions.\n",
    "    \"\"\"\n",
    "    return activations + steering_coefficient * sae.W_dec[latent_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc4c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_KWARGS = dict(temperature=0.5, freq_penalty=2.0, verbose=False)\n",
    "\n",
    "\n",
    "def generate_with_steering(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    prompt: str,\n",
    "    latent_idx: int,\n",
    "    steering_coefficient: float = 1.0,\n",
    "    max_new_tokens: int = 50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates text with steering. A multiple of the steering vector (the decoder weight for this latent) is added to\n",
    "    the last sequence position before every forward pass.\n",
    "    \"\"\"\n",
    "    _steering_hook = partial(\n",
    "        steering_hook,\n",
    "        sae=sae,\n",
    "        latent_idx=latent_idx,\n",
    "        steering_coefficient=steering_coefficient,\n",
    "    )\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sae.cfg.hook_name, _steering_hook)]):\n",
    "        output = model.generate(prompt, max_new_tokens=max_new_tokens, **GENERATE_KWARGS)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474f7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04da05e9412047358c9b00e24d50083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "gemma_2_2b = HookedSAETransformer.from_pretrained(\"gemma-2-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ddf9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Should I travel by plane or by\"\n",
    "\n",
    "no_steering_output = gemma_2_2b.generate(prompt, max_new_tokens=50, **GENERATE_KWARGS)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec05ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemmascope_sae_release = \"gemma-scope-2b-pt-res-canonical\"\n",
    "gemmascope_sae_id = \"layer_20/width_16k/canonical\"\n",
    "\n",
    "gemma_2_2b_sae = SAE.from_pretrained(gemmascope_sae_release, gemmascope_sae_id, device=str(device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df637a7",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "You'll see in the output below that the steered output includes more references to sailing and racing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd39a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2e097e143b466a88d63e7aaf78b51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating steered examples...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Steering Output                                                  </span>\n",
       "┌────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ Normal     │ Should I travel by plane or by train?                                                              │\n",
       "│            │ 1. The plane is 3 hours faster than the train.                                                     │\n",
       "│            │ 2. If you want to save money, take the bus.                                                        │\n",
       "│            │ 3. The bus is not as fast as the train but it's cheaper than the plane                             │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #0 │ Should I travel by plane or by boat?↵↵The choice of sailing or a long-distance regatta is a very   │\n",
       "│            │ personal one. The difference between the two is that on a long distance race you are in the hands  │\n",
       "│            │ of the wind and your crew, whilst in club racing you are                                           │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #1 │ Should I travel by plane or by car?↵↵There are a lot of places to visit in the South of France.    │\n",
       "│            │ You can choose your destination according to your interests, your budget and the time you have.    │\n",
       "│            │ For example, if you love the sea and sailing, you can go down                                      │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #2 │ Should I travel by plane or by car? Which is better?↵↵What do you think about the fact that we are │\n",
       "│            │ all in a race to become more and more efficient in our life? We are constantly looking for faster  │\n",
       "│            │ ways to get things done. We want to be able to do                                                  │\n",
       "└────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Steering Output                                                  \u001b[0m\n",
       "┌────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ Normal     │ Should I travel by plane or by train?                                                              │\n",
       "│            │ 1. The plane is 3 hours faster than the train.                                                     │\n",
       "│            │ 2. If you want to save money, take the bus.                                                        │\n",
       "│            │ 3. The bus is not as fast as the train but it's cheaper than the plane                             │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #0 │ Should I travel by plane or by boat?↵↵The choice of sailing or a long-distance regatta is a very   │\n",
       "│            │ personal one. The difference between the two is that on a long distance race you are in the hands  │\n",
       "│            │ of the wind and your crew, whilst in club racing you are                                           │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #1 │ Should I travel by plane or by car?↵↵There are a lot of places to visit in the South of France.    │\n",
       "│            │ You can choose your destination according to your interests, your budget and the time you have.    │\n",
       "│            │ For example, if you love the sea and sailing, you can go down                                      │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #2 │ Should I travel by plane or by car? Which is better?↵↵What do you think about the fact that we are │\n",
       "│            │ all in a race to become more and more efficient in our life? We are constantly looking for faster  │\n",
       "│            │ ways to get things done. We want to be able to do                                                  │\n",
       "└────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich import print as rprint\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "table = Table(show_header=False, show_lines=True, title=\"Steering Output\")\n",
    "table.add_row(\"Normal\", no_steering_output)\n",
    "for i in tqdm(range(3), \"Generating steered examples...\"):\n",
    "    table.add_row(\n",
    "        f\"Steered #{i}\",\n",
    "        generate_with_steering(\n",
    "            gemma_2_2b,\n",
    "            gemma_2_2b_sae,\n",
    "            prompt,\n",
    "            latent_idx,\n",
    "            steering_coefficient=240.0,  # roughly 1.5-2x the latent's max activation\n",
    "        ).replace(\"\\n\", \"↵\"),\n",
    "    )\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a378da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
